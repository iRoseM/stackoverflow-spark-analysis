package com.github.iRoseM

import org.apache.spark.sql.SparkSession

object Main {
  def main(args: Array[String]): Unit = {
    // 1. Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Spark
    val spark = SparkSession.builder()
      .appName("StackOverflow Survey Analysis")
      .master("local[*]")
      .getOrCreate()

    import spark.implicits._

    // 2. ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ù…Ù„Ù CSV
    val csvFilePath = "data/survey_results_public.csv"

    // 3. Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù CSV
    println(s"ğŸ“‚ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ù…Ù†: $csvFilePath")
    val df = spark.read
      .option("header", "true")        // Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø£ÙˆÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
      .option("inferSchema", "true")    // Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
      .csv(csvFilePath)

    // 4. Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    println(s"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ${df.count()} Ø³Ø·Ø±")
    
    println("\nğŸ“‹ --- Ø£ÙˆÙ„ 5 Ø£Ø³Ø·Ø± ---")
    df.show(5, truncate = false)
    
    println("\nğŸ“Š --- Ù…Ø®Ø·Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Schema) ---")
    df.printSchema()
    
    println("\nğŸ“ˆ --- Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø© ---")
    df.describe().show()

    // 5. Ø¥ÙŠÙ‚Ø§Ù Ø¬Ù„Ø³Ø© Spark
    spark.stop()
  }
}